{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1adb9e0-7353-4aad-8ab3-a360c55d11f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.39.3\n",
      "  Using cached transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "Requirement already satisfied: safetensors==0.4.2 in /opt/conda/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3) (2025.7.34)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3) (2.32.2)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.3)\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.3) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.3) (4.11.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.3) (1.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.39.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.39.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.39.3) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.39.3) (2024.2.2)\n",
      "Using cached transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.2\n",
      "    Uninstalling transformers-4.44.2:\n",
      "      Successfully uninstalled transformers-4.44.2\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.39.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m✅ torch: 2.8.0+cu128\n",
      "✅ transformers: 4.39.3\n",
      "✅ safetensors: 0.4.2\n"
     ]
    }
   ],
   "source": [
    "# Install only missing packages for Docker environment\n",
    "!pip install transformers==4.39.3 safetensors==0.4.2 && \\\n",
    "python -c \"import torch; print('torch:', torch.__version__)\" && \\\n",
    "python -c \"import transformers; print('transformers:', transformers.__version__)\" && \\\n",
    "python -c \"import safetensors; print('safetensors:', safetensors.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "235ff51e-f1ea-4780-af15-da5882aa8eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab94e2f2-10a6-464c-8ac0-c16da39d4ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.6 in /opt/conda/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.6) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.10/site-packages (from triton==3.4.0->torch>=2.6) (69.5.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.6) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.6) (2.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade \"torch>=2.6\" torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a83be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.quantization import quantize_dynamic\n",
    "import torch.nn.utils.prune as prune\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from datasets import Dataset as HFDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386bd77-f21c-432a-acef-435c3f17dc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing PyTorch checkpoint loading...\n",
      "\n",
      "1. Testing DeBERTa checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at agentlans/deberta-v3-base-tweet-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DeBERTa checkpoint loaded successfully!\n",
      "   Model type: DebertaV2ForSequenceClassification\n",
      "   Number of parameters: 184,425,989\n",
      "\n",
      "2. Testing RoBERTa checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RoBERTa checkpoint loaded successfully!\n",
      "   Model type: RobertaForSequenceClassification\n",
      "   Number of parameters: 124,649,477\n",
      "\n",
      "==================================================\n",
      "Checkpoint test completed!\n"
     ]
    }
   ],
   "source": [
    "# Quick test to verify PyTorch checkpoints load correctly\n",
    "def test_checkpoints():\n",
    "    print(\"Testing PyTorch checkpoint loading...\")\n",
    "\n",
    "    # Test DeBERTa checkpoint\n",
    "    try:\n",
    "        print(\"\\n1. Testing DeBERTa checkpoint...\")\n",
    "        deberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"agentlans/deberta-v3-base-tweet-sentiment\",\n",
    "            num_labels=5,ignore_mismatched_sizes=True\n",
    "        )\n",
    "        ckpt = torch.load(\n",
    "            \"/storage/yagel/ADL/checkpoints/deberta_hp_tuning_study/best_model/best_model.pt\",\n",
    "            map_location=\"cpu\"\n",
    "        )\n",
    "        deberta_model.load_state_dict(ckpt['model_state_dict'], strict=False)\n",
    "        print(\"DeBERTa checkpoint loaded successfully!\")\n",
    "        print(f\"   Model type: {type(deberta_model).__name__}\")\n",
    "        print(f\"   Number of parameters: {sum(p.numel() for p in deberta_model.parameters()):,}\")\n",
    "        del deberta_model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"DeBERTa checkpoint failed: {e}\")\n",
    "\n",
    "    # Test RoBERTa checkpoint\n",
    "    try:\n",
    "        print(\"\\n2. Testing RoBERTa checkpoint...\")\n",
    "        roberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "            num_labels=5,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        ckpt = torch.load(\n",
    "            \"/storage/yagel/ADL/checkpoints/roberta_hp_tuning_study/best_model/best_model.pt\",\n",
    "            map_location=\"cpu\"\n",
    "        )\n",
    "        roberta_model.load_state_dict(ckpt['model_state_dict'], strict=False)\n",
    "        print(\"RoBERTa checkpoint loaded successfully!\")\n",
    "        print(f\"   Model type: {type(roberta_model).__name__}\")\n",
    "        print(f\"   Number of parameters: {sum(p.numel() for p in roberta_model.parameters()):,}\")\n",
    "        del roberta_model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"RoBERTa checkpoint failed: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Checkpoint test completed!\")\n",
    "\n",
    "# Run the test\n",
    "test_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dedaf9-ee20-4b0b-bdc3-96e9d4501835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HuggingFace checkpoints...\n",
      "\n",
      "1. Testing DeBERTa HF checkpoint...\n",
      "✅ DeBERTa HF checkpoint loaded successfully!\n",
      "   Model type: DebertaV2ForSequenceClassification\n",
      "   Number of parameters: 184,425,989\n",
      "\n",
      "2. Testing RoBERTa HF checkpoint...\n",
      "✅ RoBERTa HF checkpoint loaded successfully!\n",
      "   Model type: RobertaForSequenceClassification\n",
      "   Number of parameters: 124,649,477\n",
      "\n",
      "==================================================\n",
      "HF Checkpoint test completed!\n"
     ]
    }
   ],
   "source": [
    "# Test loading HuggingFace checkpoints for RoBERTa and DeBERTa\n",
    "\n",
    "def test_hf_checkpoints():\n",
    "    print(\"Testing HuggingFace checkpoints...\")\n",
    "\n",
    "    # Test DeBERTa HF checkpoint\n",
    "    try:\n",
    "        print(\"\\n1. Testing DeBERTa HF checkpoint...\")\n",
    "        deberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"/storage/yagel/ADL/deberta_results_HF/deberta_trial_4/checkpoint-4950\"\n",
    "        )\n",
    "        print(\"DeBERTa HF checkpoint loaded successfully!\")\n",
    "        print(f\"   Model type: {type(deberta_model).__name__}\")\n",
    "        print(f\"   Number of parameters: {sum(p.numel() for p in deberta_model.parameters()):,}\")\n",
    "        del deberta_model\n",
    "    except Exception as e:\n",
    "        print(f\"DeBERTa HF checkpoint failed: {e}\")\n",
    "\n",
    "    # Test RoBERTa HF checkpoint\n",
    "    try:\n",
    "        print(\"\\n2. Testing RoBERTa HF checkpoint...\")\n",
    "        roberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"/storage/yagel/ADL/roberta_results_HF/trial_7/checkpoint-18000\"\n",
    "        )\n",
    "        print(\"RoBERTa HF checkpoint loaded successfully!\")\n",
    "        print(f\"   Model type: {type(roberta_model).__name__}\")\n",
    "        print(f\"   Number of parameters: {sum(p.numel() for p in roberta_model.parameters()):,}\")\n",
    "        del roberta_model\n",
    "    except Exception as e:\n",
    "        print(f\"RoBERTa HF checkpoint failed: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"HF Checkpoint test completed!\")\n",
    "\n",
    "# Run the test\n",
    "test_hf_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d9b9b-3718-4da7-9daa-7074f9822d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HF Model 1 - DeBERTa...\n"
     ]
    }
   ],
   "source": [
    "def load_models():\n",
    "    models = {}\n",
    "\n",
    "    # Model 1: HuggingFace checkpoint 1 - DeBERTa (from checkpoint directory)\n",
    "    print(\"Loading HF Model 1 - DeBERTa...\")\n",
    "    models['hf_deberta'] = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"/storage/yagel/ADL/deberta_results_HF/deberta_trial_4/checkpoint-4950\"\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Model 2: HuggingFace checkpoint 2 - RoBERTa (from checkpoint directory)\n",
    "    print(\"Loading HF Model 2 - RoBERTa...\")\n",
    "    models['hf_roberta'] = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"/storage/yagel/ADL/roberta_results_HF/trial_7/checkpoint-18000\"\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # Model 3: PyTorch checkpoint 1 - DeBERTa (fine-tuned)\n",
    "    print(\"Loading PT Model 1 - DeBERTa (fine-tuned)...\")\n",
    "    models['pt_deberta'] = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"agentlans/deberta-v3-base-tweet-sentiment\",\n",
    "        num_labels=5,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    deberta_ckpt = torch.load(\"/storage/yagel/ADL/checkpoints/deberta_hp_tuning_study/best_model/best_model.pt\", map_location=DEVICE)\n",
    "    models['pt_deberta'].load_state_dict(deberta_ckpt['model_state_dict'], strict=False)\n",
    "    models['pt_deberta'] = models['pt_deberta'].to(DEVICE)\n",
    "\n",
    "    # Model 4: PyTorch checkpoint 2 - RoBERTa (fine-tuned)\n",
    "    print(\"Loading PT Model 2 - RoBERTa (fine-tuned)...\")\n",
    "    models['pt_roberta'] = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "        num_labels=5,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    roberta_ckpt = torch.load(\"/storage/yagel/ADL/checkpoints/roberta_hp_tuning_study/best_model/best_model.pt\", map_location=DEVICE)\n",
    "    models['pt_roberta'].load_state_dict(roberta_ckpt['model_state_dict'], strict=False)\n",
    "    models['pt_roberta'] = models['pt_roberta'].to(DEVICE)\n",
    "\n",
    "    return models\n",
    "\n",
    "# Load all models\n",
    "models = load_models()\n",
    "print(f\"Loaded {len(models)} models: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d6ca0-22ae-4cf1-b0a7-ce17caf844ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b07b1-34b0-4bfd-8f4f-cbab1ec16072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train_df.csv\")\n",
    "eval_df  = pd.read_csv(\"data/eval_df.csv\")\n",
    "test_df  = pd.read_csv(\"data/test_df.csv\")\n",
    "\n",
    "# ensure int labels, keep your columns\n",
    "for df in (train_df, eval_df, test_df):\n",
    "    df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\").astype(int)\n",
    "    assert df[\"label\"].between(0, 4).all(), f\"Labels out of range in {df.shape}: {set(df['label'])}\"\n",
    "\n",
    "train_df = train_df[[\"CleanTweet\",\"label\"]].reset_index(drop=True)\n",
    "eval_df  = eval_df[[\"CleanTweet\",\"label\"]].reset_index(drop=True)\n",
    "test_df  = test_df[[\"CleanTweet\",\"label\"]].reset_index(drop=True)\n",
    "\n",
    "class TweetsDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=256):\n",
    "        self.texts = dataframe[\"CleanTweet\"].tolist()\n",
    "        self.labels = dataframe[\"label\"].astype(int).tolist()  # ensure plain ints\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),       # squeeze batch dim only\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"agentlans/deberta-v3-base-tweet-sentiment\", use_fast=False)\n",
    "\n",
    "train_dataset = TweetsDataset(train_df, tokenizer)\n",
    "val_dataset   = TweetsDataset(eval_df,  tokenizer)\n",
    "test_dataset  = TweetsDataset(test_df,  tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=5, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=5, shuffle=False)\n",
    "\n",
    "print(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6839d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from checkpoint\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load base DeBERTa-v3 tweet sentiment model first, then load your trained weights\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'agentlans/deberta-v3-base-tweet-sentiment',  # CHANGE: Update to match your model architecture (e.g., 'bert-base-uncased', 'roberta-base')\n",
    "    num_labels=5,              # CHANGE: Update number of labels to match your task\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Load your trained checkpoint weights\n",
    "checkpoint_path = \"checkpoints/deberta_hp_tuning_study/best_model/best_model.pt\"  #manual code  CHANGE: Update path to your checkpoint file\n",
    "checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "\n",
    "# Extract model weights from checkpoint metadata\n",
    "if 'model_state_dict' in checkpoint:\n",
    "    model_weights = checkpoint['model_state_dict']\n",
    "    print(f\"Loaded checkpoint metadata - Study: {checkpoint.get('study_name', 'N/A')}\")\n",
    "    print(f\"Best trial: {checkpoint.get('study_best_trial', 'N/A')}, Best accuracy: {checkpoint.get('best_val_accuracy', 'N/A')}\")\n",
    "else:\n",
    "    model_weights = checkpoint\n",
    "\n",
    "model.load_state_dict(model_weights)\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f\"Model loaded from: {checkpoint_path}\")\n",
    "print(f\"Model loaded on {DEVICE}\")\n",
    "print(f\"Model type: {type(model).__name__}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e0a4c-58c1-4bc2-8651-348487b96c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ef23b",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a61891-5531-4963-8308-3caa5be4ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to measure model size in KB\n",
    "def get_model_size(model, filename=\"temp.pth\"):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    size = os.path.getsize(filename) / 1024  # KB\n",
    "    # Clean up temporary file\n",
    "    os.remove(filename)\n",
    "    return size\n",
    "\n",
    "# Function to evaluate accuracy\n",
    "def evaluate_accuracy(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}  # Move everything to the device\n",
    "\n",
    "            outputs = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "            predictions = outputs.logits.argmax(dim=1)\n",
    "            correct += (predictions == batch[\"labels\"]).sum().item()\n",
    "            total += batch[\"labels\"].size(0)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "# --- Main test loop ---\n",
    "def quantization_sweep(model, test_loader):\n",
    "    results = []\n",
    "\n",
    "    # Original FP32 model on GPU\n",
    "    model.eval()\n",
    "    fp32_size = get_model_size(model, \"fp32.pth\")\n",
    "    fp32_acc = evaluate_accuracy(model, test_loader, DEVICE)\n",
    "    results.append((\"FP32 (baseline)\", fp32_size, fp32_acc, 0.0))\n",
    "\n",
    "    # INT8 Dynamic quantization (Linear layers only)\n",
    "    # Move model to CPU for quantization\n",
    "    model_cpu = model.cpu()\n",
    "    int8_model = quantize_dynamic(model_cpu, {nn.Linear}, dtype=torch.qint8)\n",
    "    int8_size = get_model_size(int8_model, \"int8.pth\")\n",
    "    \n",
    "    # Evaluate quantized model on CPU (quantized models can't run on GPU)\n",
    "    int8_acc = evaluate_accuracy(int8_model, test_loader, torch.device('cpu'))\n",
    "    results.append((\"INT8 Linear\", int8_size, int8_acc, 100*(1 - int8_size/fp32_size)))\n",
    "\n",
    "    # Move original model back to GPU\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{'Format':<15} {'Size (KB)':<12} {'Accuracy':<10} {'% Size Saved':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    for name, size, acc, saving in results:\n",
    "        print(f\"{name:<15} {size:<12.1f} {acc:<10.4f} {saving:<12.1f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d3769-03d1-4c23-aee9-68a799b34b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeBERTA manual code (pt checkpoint)\n",
    "model.to(DEVICE)\n",
    "results = quantization_sweep(model, test_loader)\n",
    "print(\"Quantization results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565593a-70cf-4f22-aee3-04187cf55647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RoBERTA manual (pt checkpoint)\n",
    "# Paths & backbone\n",
    "roberta_backbone = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "roberta_ckpt     = \"checkpoints/roberta_hp_tuning_study/best_model/best_model.pt\"\n",
    "\n",
    "# Build loader with the **matching tokenizer**\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_backbone, use_fast=True)\n",
    "test_dataset = TweetsDataset(test_df, roberta_tokenizer, max_length=256)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Optional: sanity on label range for 5 classes\n",
    "assert test_df[\"label\"].between(0, 4).all(), \"Labels must be in [0..4] for num_labels=5.\"\n",
    "invalid_labels = test_df[~test_df[\"label\"].between(0, 4)]\n",
    "if not invalid_labels.empty:\n",
    "    print(\"❌ Invalid labels found:\\n\", invalid_labels)\n",
    "    raise ValueError(\"Test set contains invalid labels.\")\n",
    "\n",
    "# Load model + weights\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    roberta_backbone, num_labels=5, ignore_mismatched_sizes=True\n",
    ")\n",
    "state = torch.load(roberta_ckpt, map_location=DEVICE)\n",
    "roberta_model.load_state_dict(state[\"model_state_dict\"])\n",
    "roberta_model.eval()\n",
    "roberta_model = roberta_model.to(DEVICE)\n",
    "\n",
    "# Sanity check: token IDs fit vocab\n",
    "batch = next(iter(test_loader))\n",
    "max_id = int(batch[\"input_ids\"].max())\n",
    "vocab_sz = roberta_model.roberta.embeddings.word_embeddings.num_embeddings\n",
    "print(f\"Max token id = {max_id} | vocab size = {vocab_sz}\")\n",
    "assert max_id < vocab_sz, \"Token ID exceeds model vocab size – tokenizer/model mismatch.\"\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "roberta_model.to(DEVICE)\n",
    "results = quantization_sweep(roberta_model, test_loader)\n",
    "\n",
    "print(\"RoBERTa (PT) Quantization results:\", results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012488f-415c-4943-b6e8-1922b9e15ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# DeBERTa: HF checkpoint + sweep\n",
    "# ===============================\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# DeBERTa paths and backbone\n",
    "deberta_backbone = \"agentlans/deberta-v3-base-tweet-sentiment\"  # Or your custom one if different\n",
    "\n",
    "# Tokenizer and loader\n",
    "deberta_tokenizer = AutoTokenizer.from_pretrained(deberta_backbone, use_fast=True)\n",
    "test_dataset = TweetsDataset(test_df, deberta_tokenizer, max_length=256)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Sanity check: label range\n",
    "assert test_df[\"label\"].between(0, 4).all(), \"Labels must be in [0..4] for num_labels=5.\"\n",
    "\n",
    "# Load model\n",
    "deberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"deberta_results_HF/deberta_trial_4/checkpoint-4950\", num_labels=5\n",
    ")\n",
    "\n",
    "\n",
    "# Run sweep on CPU\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "deberta_model.to(DEVICE)\n",
    "results = quantization_sweep(deberta_model, test_loader)\n",
    "print(\"DeBERTa (HF) Quantization results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0058696-48a7-47fb-8d71-837eb03ebdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# RoBERTa: HF CHECKPOINT + SWEEP\n",
    "# ===============================\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Tokenizer from base model\n",
    "roberta_backbone = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_backbone, use_fast=True)\n",
    "\n",
    "# Loader\n",
    "test_dataset = TweetsDataset(test_df, roberta_tokenizer, max_length=256)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Sanity check\n",
    "assert test_df[\"label\"].between(0, 4).all(), \"Labels must be in [0..4] for num_labels=5.\"\n",
    "\n",
    "# ✅ Load model from local HF checkpoint\n",
    "roberta_ckpt = \"roberta_results_HF/trial_7/checkpoint-18000\"\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    roberta_ckpt,\n",
    "    num_labels=5,\n",
    "    local_files_only=True  # <<< this tells HF to treat the path as local\n",
    ")\n",
    "\n",
    "# Run sweep\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "roberta_model.to(DEVICE)\n",
    "results = quantization_sweep(roberta_model, test_loader)\n",
    "\n",
    "print(\"RoBERTa (HF checkpoint) Quantization results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a39f8-b648-400d-aa41-5d6854e796d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5336d7c1",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a4842-5f67-43bc-b4d1-8a9484aff931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def pruning_tradeoff_sweep_cpu(model, test_loader, amounts=None):\n",
    "    \"\"\"\n",
    "    CPU-only pruning sweep with results table and plot\n",
    "    \n",
    "    Args:\n",
    "        model: Input model to prune\n",
    "        test_loader: DataLoader for evaluation\n",
    "        amounts: List of pruning amounts (default: 10%, 20%, 30%, 40%, 50%)\n",
    "    \n",
    "    Returns:\n",
    "        results: List of dictionaries with pruning results\n",
    "    \"\"\"\n",
    "    if amounts is None:\n",
    "        amounts = [0.1, 0.2, 0.3, 0.4, 0.5]  # 10%, 20%, 30%, 40%, 50%\n",
    "    \n",
    "    print(\"🔬 Starting CPU Pruning Sweep\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for amount in amounts:\n",
    "        print(f\"\\n📊 Testing pruning amount: {amount*100:.0f}%\")\n",
    "        \n",
    "        # Create a copy of the model for this pruning amount\n",
    "        model_to_prune = copy.deepcopy(model)\n",
    "        \n",
    "        # Get parameters to prune (all Linear layers)\n",
    "        parameters_to_prune = []\n",
    "        for name, module in model_to_prune.named_modules():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                parameters_to_prune.append((module, 'weight'))\n",
    "        \n",
    "        print(f\"Found {len(parameters_to_prune)} Linear layers to prune\")\n",
    "        \n",
    "        # Apply global unstructured pruning\n",
    "        prune.global_unstructured(\n",
    "            parameters_to_prune,\n",
    "            pruning_method=prune.L1Unstructured,\n",
    "            amount=amount\n",
    "        )\n",
    "        \n",
    "        # Calculate sparsity\n",
    "        total_params = 0\n",
    "        zero_params = 0\n",
    "        for name, module in model_to_prune.named_modules():\n",
    "            if isinstance(module, torch.nn.Linear) and hasattr(module, 'weight_mask'):\n",
    "                total_params += module.weight.numel()\n",
    "                zero_params += (module.weight_mask == 0).sum().item()\n",
    "        \n",
    "        actual_sparsity = zero_params / total_params if total_params > 0 else 0\n",
    "        print(f\"Actual sparsity: {actual_sparsity:.3f} ({actual_sparsity*100:.1f}%)\")\n",
    "        \n",
    "        # Evaluate accuracy on CPU\n",
    "        acc = evaluate_accuracy_cpu(model_to_prune, test_loader)\n",
    "        \n",
    "        results.append({\n",
    "            'pruning_amount': amount,\n",
    "            'actual_sparsity': actual_sparsity,\n",
    "            'accuracy': acc\n",
    "        })\n",
    "        \n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        \n",
    "        # Clean up\n",
    "        del model_to_prune\n",
    "    \n",
    "    # Print final results table\n",
    "    print(\"\\n📈 PRUNING RESULTS SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Pruning | Actual  | Accuracy\")\n",
    "    print(\"Amount  | Sparsity|         \")\n",
    "    print(\"-\" * 50)\n",
    "    for result in results:\n",
    "        print(f\"{result['pruning_amount']*100:6.0f}% | {result['actual_sparsity']*100:6.1f}%  | {result['accuracy']:.4f}\")\n",
    "    \n",
    "    # Create plot\n",
    "    print(\"\\n📊 Generating plot...\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results_df['actual_sparsity'] * 100, results_df['accuracy'], 'bo-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Sparsity (%)', fontsize=12)\n",
    "    plt.ylabel('Accuracy', fontsize=12)\n",
    "    plt.title('Model Pruning: Sparsity vs Accuracy Trade-off', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(range(10, 60, 10))\n",
    "    \n",
    "    # Add accuracy values as annotations\n",
    "    for i, row in results_df.iterrows():\n",
    "        plt.annotate(f'{row[\"accuracy\"]:.3f}', \n",
    "                    (row['actual_sparsity']*100, row['accuracy']), \n",
    "                    textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Pruning analysis complete!\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_accuracy_cpu(model, test_loader):\n",
    "    \"\"\"\n",
    "    CPU-only accuracy evaluation\n",
    "    \n",
    "    Args:\n",
    "        model: Model to evaluate\n",
    "        test_loader: DataLoader for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Float accuracy value\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de6cc4-ec20-4daa-9b07-4a74e5e5e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# RoBERTa: PT checkpoint + PRUNING (CPU)\n",
    "# ===============================\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Backbone + PT checkpoint path\n",
    "roberta_backbone = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"  # 3-class base head\n",
    "roberta_pt_ckpt  =  \"checkpoints/roberta_hp_tuning_study/best_model/best_model.pt\"\n",
    "\n",
    "# Tokenizer & loader\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_backbone, use_fast=True)\n",
    "test_dataset = TweetsDataset(test_df, roberta_tokenizer, max_length=256)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Load base arch w/ new 5-class head, then load your fine-tuned PT weights\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    roberta_backbone, num_labels=5, ignore_mismatched_sizes=True\n",
    ")\n",
    "state = torch.load(roberta_pt_ckpt, map_location=DEVICE)\n",
    "roberta_model.load_state_dict(state[\"model_state_dict\"], strict=False)\n",
    "roberta_model.to(DEVICE).eval()\n",
    "\n",
    "# Run CPU pruning sweep\n",
    "pruning_results_roberta_pt = pruning_tradeoff_sweep_cpu(\n",
    "    roberta_model, test_loader, amounts=[0.1, 0.2, 0.3, 0.4, 0.5]\n",
    ")\n",
    "pruning_results_roberta_pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2f21c-066e-436f-abfb-548ae09ca317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# RoBERTa: HF checkpoint dir + PRUNING (CPU)\n",
    "# ===============================\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Your HF checkpoint directory\n",
    "roberta_hf_ckpt = \"roberta_results_HF/trial_7/checkpoint-18000\"\n",
    "\n",
    "# Use tokenizer from backbone (checkpoint dir may not have tokenizer files)\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\", use_fast=True)\n",
    "test_dataset = TweetsDataset(test_df, roberta_tokenizer, max_length=256)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Load model from local HF checkpoint dir\n",
    "roberta_model_hf = AutoModelForSequenceClassification.from_pretrained(\n",
    "    roberta_hf_ckpt, local_files_only=True\n",
    ")\n",
    "# (optional) enforce 5 labels if config differs\n",
    "if roberta_model_hf.config.num_labels != 5:\n",
    "    roberta_model_hf.classifier.out_proj = torch.nn.Linear(\n",
    "        roberta_model_hf.classifier.out_proj.in_features, 5\n",
    "    )\n",
    "    roberta_model_hf.config.num_labels = 5\n",
    "\n",
    "roberta_model_hf.to(DEVICE).eval()\n",
    "\n",
    "# Run CPU pruning sweep\n",
    "pruning_results_roberta_hf = pruning_tradeoff_sweep_cpu(\n",
    "    roberta_model_hf, test_loader, amounts=[0.1, 0.2, 0.3, 0.4, 0.5]\n",
    ")\n",
    "pruning_results_roberta_hf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49067d11-9223-40e8-b989-ff1c5bb3ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# DeBERTa: HF checkpoint dir + PRUNING (CPU)\n",
    "# ===============================\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# HF checkpoint directory you trained with Trainer.save_model / checkpoint-*\n",
    "deberta_hf_ckpt = \"deberta_results_HF/deberta_trial_4/checkpoint-4950\"\n",
    "\n",
    "# Use tokenizer from backbone (checkpoint dir often lacks tokenizer files)\n",
    "deberta_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\", use_fast=True)\n",
    "test_dataset = TweetsDataset(test_df, deberta_tokenizer, max_length=256)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Load model weights from local HF checkpoint dir\n",
    "deberta_model_hf = AutoModelForSequenceClassification.from_pretrained(\n",
    "    deberta_hf_ckpt, local_files_only=True   # treat as local path\n",
    ")\n",
    "# (optional) enforce num_labels=5 if your config wasn’t saved with 5:\n",
    "if deberta_model_hf.config.num_labels != 5:\n",
    "    deberta_model_hf.classifier = torch.nn.Linear(deberta_model_hf.classifier.in_features, 5)\n",
    "    deberta_model_hf.config.num_labels = 5\n",
    "\n",
    "deberta_model_hf.to(DEVICE).eval()\n",
    "\n",
    "# Run CPU pruning sweep\n",
    "pruning_results_deberta_hf = pruning_tradeoff_sweep_cpu(\n",
    "    deberta_model_hf, test_loader, amounts=[0.1, 0.2, 0.3, 0.4, 0.5]\n",
    ")\n",
    "pruning_results_deberta_hf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d125e6f-fec1-4240-b6b0-c472d00b685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# DeBERTa: PT checkpoint + PRUNING (CPU)\n",
    "# ===============================\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Backbone + PT checkpoint path\n",
    "deberta_backbone = \"agentlans/deberta-v3-base-tweet-sentiment\"\n",
    "deberta_pt_ckpt  = \"checkpoints/deberta_hp_tuning_study/best_model/best_model.pt\"\n",
    "\n",
    "# Tokenizer & loader (use backbone tokenizer)\n",
    "deberta_tokenizer = AutoTokenizer.from_pretrained(deberta_backbone, use_fast=True)\n",
    "test_dataset = TweetsDataset(test_df, deberta_tokenizer, max_length=256)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Load base arch then your fine-tuned PT weights\n",
    "deberta_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    deberta_backbone, num_labels=5, ignore_mismatched_sizes=True\n",
    ")\n",
    "state = torch.load(deberta_pt_ckpt, map_location=DEVICE)\n",
    "deberta_model.load_state_dict(state[\"model_state_dict\"], strict=False)\n",
    "deberta_model.to(DEVICE).eval()\n",
    "\n",
    "# Run CPU pruning sweep (10–50%)\n",
    "pruning_results_deberta_pt = pruning_tradeoff_sweep_cpu(\n",
    "    deberta_model, test_loader, amounts=[0.1, 0.2, 0.3, 0.4, 0.5]\n",
    ")\n",
    "pruning_results_deberta_pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dee4b0",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f57941-e361-4cc9-803e-421b57567c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b97195-9fb9-4627-acbc-c485c6af7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d16731a-9072-45b8-98f8-1fff497b5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b067d6c-8f42-472c-ae61-676cdcb5ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset as HFDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "def perform_knowledge_distillation(teacher_model, teacher_name, train_df, eval_df, device, \n",
    "                                 temperature=2.0, alpha=0.5, num_epochs=5, batch_size=64):\n",
    "\n",
    "    \n",
    "    print(f\"\\nStarting knowledge distillation with teacher: {teacher_name}\")\n",
    "    \n",
    "    # Convert pandas DataFrames to Hugging Face Datasets\n",
    "    train_hf_dataset = HFDataset.from_pandas(train_df)\n",
    "    eval_hf_dataset = HFDataset.from_pandas(eval_df)\n",
    "    \n",
    "    # Set up tokenizer (use student tokenizer for tokenization)\n",
    "    student_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n",
    "    \n",
    "    # Tokenization function\n",
    "    def tokenize_function(examples):\n",
    "        return student_tokenizer(examples[\"CleanTweet\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "    \n",
    "    # Tokenize datasets\n",
    "    tokenized_train = train_hf_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_eval = eval_hf_dataset.map(tokenize_function, batched=True)\n",
    "    \n",
    "    # Compute metrics function\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return {\n",
    "            'accuracy': accuracy_score(labels, predictions),\n",
    "            'f1': f1_score(labels, predictions, average='weighted'),\n",
    "            'precision': precision_score(labels, predictions, average='weighted'),\n",
    "            'recall': recall_score(labels, predictions, average='weighted')\n",
    "        }\n",
    "    \n",
    "    # Define DistillationTrainer\n",
    "    class DistillationTrainer(Trainer):\n",
    "        def __init__(self, *args, teacher_model=None, temperature=2.0, alpha=0.5, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.teacher = teacher_model\n",
    "            if self.teacher is not None:\n",
    "                self.teacher.eval()\n",
    "            self.temperature = temperature\n",
    "            self.alpha = alpha\n",
    "        \n",
    "        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            outputs_student = model(**inputs)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs_teacher = self.teacher(**inputs)\n",
    "            \n",
    "            # Cross entropy loss\n",
    "            loss_ce = F.cross_entropy(outputs_student.logits, labels)\n",
    "            \n",
    "            # KL divergence loss\n",
    "            loss_kl = F.kl_div(\n",
    "                F.log_softmax(outputs_student.logits / self.temperature, dim=-1),\n",
    "                F.softmax(outputs_teacher.logits / self.temperature, dim=-1),\n",
    "                reduction=\"batchmean\"\n",
    "            ) * (self.temperature ** 2)\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = self.alpha * loss_ce + (1 - self.alpha) * loss_kl\n",
    "            \n",
    "            return (loss, outputs_student) if return_outputs else loss\n",
    "    \n",
    "    # Create fresh student model\n",
    "    student = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=5\n",
    "    ).to(device)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./distilled_model_{teacher_name}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",                      # Don't save any checkpoints\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=500,\n",
    "        report_to=[],                        # Don't report to wandb/tensorboard\n",
    "    )\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = DistillationTrainer(\n",
    "        model=student,\n",
    "        teacher_model=teacher_model.to(device),\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=student_tokenizer,\n",
    "        temperature=temperature,\n",
    "        alpha=alpha\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate\n",
    "    print(f\"Training student model with {teacher_name} teacher...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    print(f\"Evaluating distilled model...\")\n",
    "    eval_result = trainer.evaluate()\n",
    "    eval_result['teacher_model'] = teacher_name\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Results for {teacher_name}:\")\n",
    "    for key, value in eval_result.items():\n",
    "        if key.startswith('eval_'):\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "    \n",
    "    # Save results to files\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    results_dir = \"./distillation_results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Save detailed results as JSON\n",
    "    results_file = os.path.join(results_dir, f\"{teacher_name}_results.json\")\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert numpy types to native Python types for JSON serialization\n",
    "        json_results = {}\n",
    "        for key, value in eval_result.items():\n",
    "            if hasattr(value, 'item'):  # numpy types\n",
    "                json_results[key] = value.item()\n",
    "            else:\n",
    "                json_results[key] = value\n",
    "        json.dump(json_results, f, indent=2)\n",
    "    \n",
    "    # Save summary results as CSV\n",
    "    summary_file = os.path.join(results_dir, f\"{teacher_name}_summary.csv\")\n",
    "    import pandas as pd\n",
    "    summary_df = pd.DataFrame([eval_result])\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    \n",
    "    # Save key metrics as text file for easy reading\n",
    "    metrics_file = os.path.join(results_dir, f\"{teacher_name}_metrics.txt\")\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write(f\"Knowledge Distillation Results for {teacher_name}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        for key, value in eval_result.items():\n",
    "            if key.startswith('eval_'):\n",
    "                f.write(f\"{key}: {value:.4f}\\n\")\n",
    "        f.write(f\"\\nTeacher Model: {teacher_name}\\n\")\n",
    "        f.write(f\"Student Model: distilbert-base-uncased\\n\")\n",
    "        f.write(f\"Training Epochs: {num_epochs}\\n\")\n",
    "        f.write(f\"Batch Size: {batch_size}\\n\")\n",
    "        f.write(f\"Temperature: {temperature}\\n\")\n",
    "        f.write(f\"Alpha: {alpha}\\n\")\n",
    "    \n",
    "    print(f\"Results saved:\")\n",
    "    print(f\"  - JSON: {results_file}\")\n",
    "    print(f\"  - CSV: {summary_file}\")\n",
    "    print(f\"  - Text: {metrics_file}\")\n",
    "    \n",
    "    return eval_result\n",
    "\n",
    "print(\"Knowledge distillation function loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adf670-1f55-48b5-965b-3f07d298f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Distillation: DeBERTa HF → DistilBERT Student\n",
    "# ===============================\n",
    "\n",
    "# Load your DeBERTa HF checkpoint\n",
    "teacher_path = \"deberta_results_HF/deberta_trial_4/checkpoint-4950\"\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher_path,\n",
    "    num_labels=5,\n",
    "    local_files_only=True\n",
    ").to(DEVICE).eval()\n",
    "\n",
    "print(\"🔥 Distilling from DeBERTa HF (local checkpoint)\")\n",
    "\n",
    "# Perform distillation using the function\n",
    "result_deberta_hf = perform_knowledge_distillation(\n",
    "    teacher_model=teacher_model,\n",
    "    teacher_name=\"DeBERTa_HF\",\n",
    "    train_df=train_df,\n",
    "    eval_df=eval_df,\n",
    "    device=DEVICE,\n",
    "    num_epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"✅ Completed distillation with DeBERTa HF model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ef2f9-0a0e-4246-8616-ab59a677a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔥 Distilling from: RoBERTa HF\")\n",
    "# Load your custom trained RoBERTa model\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"cardiffnlp/twitter-roberta-base-sentiment-latest\", \n",
    "    num_labels=5, \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "ckpt = torch.load(\"checkpoints/roberta_hp_tuning_study/best_model/best_model.pt\", map_location=DEVICE)\n",
    "teacher_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "teacher_model = teacher_model.to(DEVICE)\n",
    "\n",
    "# Perform distillation using the function\n",
    "result_deberta = perform_knowledge_distillation(\n",
    "    teacher_model=teacher_model,\n",
    "    teacher_name=\"RoBERTa_PT\",\n",
    "    train_df=train_df,\n",
    "    eval_df=eval_df,\n",
    "    device=DEVICE,\n",
    "    num_epochs=5,\n",
    "    batch_size=64  \n",
    ")\n",
    "\n",
    "print(f\"✅ Completed distillation with DeBERTa PT model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07daa3-45f1-4aa9-9132-4781ec3233f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔥 Distilling from: DeBERTa HF\")\n",
    "# Load your custom trained DeBERTa model\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"agentlans/deberta-v3-base-tweet-sentiment\", \n",
    "    num_labels=5, \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "ckpt = torch.load(\"checkpoints/deberta_hp_tuning_study/best_model/best_model.pt\", map_location=DEVICE)\n",
    "teacher_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "teacher_model = teacher_model.to(DEVICE)\n",
    "\n",
    "# Perform distillation using the function\n",
    "result_deberta = perform_knowledge_distillation(\n",
    "    teacher_model=teacher_model,\n",
    "    teacher_name=\"DeBERTa_PT\",\n",
    "    train_df=train_df,\n",
    "    eval_df=eval_df,\n",
    "    device=DEVICE,\n",
    "    num_epochs=5,\n",
    "    batch_size=32  # Using 32 like your original code\n",
    ")\n",
    "\n",
    "print(f\"✅ Completed distillation with DeBERTa PT model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2ed69-00dd-4293-9583-69f62e727d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your custom trained RoBERTa model from HF checkpoint\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"roberta_results_HF/trial_7/checkpoint-18000\",\n",
    "    num_labels=5,\n",
    "    local_files_only=True\n",
    ").to(DEVICE)\n",
    "\n",
    "print(\"🔥 Distilling from: RoBERTa HF\")\n",
    "\n",
    "# Perform distillation using the function\n",
    "result_roberta_hf = perform_knowledge_distillation(\n",
    "    teacher_model=teacher_model,\n",
    "    teacher_name=\"RoBERTa_HF\",\n",
    "    train_df=train_df,\n",
    "    eval_df=eval_df,\n",
    "    device=DEVICE,\n",
    "    num_epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"✅ Completed distillation with RoBERTa HF model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
