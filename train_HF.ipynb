{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178ac962-18db-482f-8650-c83fe88d746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.1.3 in /opt/conda/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy==1.26.3 in /opt/conda/lib/python3.10/site-packages (1.26.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.9.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.10/site-packages (1.9.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers==4.44.2 in /opt/conda/lib/python3.10/site-packages (4.44.2)\n",
      "Requirement already satisfied: safetensors==0.4.2 in /opt/conda/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: accelerate==0.33.0 in /opt/conda/lib/python3.10/site-packages (0.33.0)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.1.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.1.3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.1.3) (2024.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.2) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.2) (2025.7.34)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.2) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.2) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.2) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.33.0) (5.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.10/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.10/site-packages (from triton==3.4.0->torch) (69.5.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.31)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.27.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.6.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.44.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.44.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.44.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.44.2) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m✅ torch: 2.8.0+cu128\n",
      "✅ transformers: 4.44.2\n",
      "✅ safetensors: 0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==2.1.3 numpy==1.26.3 matplotlib seaborn wordcloud scikit-learn torch torchvision torchaudio transformers==4.44.2 safetensors==0.4.2 datasets optuna wandb sentencepiece accelerate==0.33.0 evaluate && \\\n",
    "python -c \"import torch; print('✅ torch:', torch.__version__)\" && \\\n",
    "python -c \"import transformers; print('✅ transformers:', transformers.__version__)\" && \\\n",
    "python -c \"import safetensors; print('✅ safetensors:', safetensors.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12123693-96a2-4f38-98cf-b68c6c9b5be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, RobertaForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import evaluate\n",
    "import time\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainerCallback,\n",
    "    )\n",
    "from torch.utils.data import Dataset\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "print(\"All imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a3dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train_df.csv\")\n",
    "eval_df  = pd.read_csv(\"data/eval_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc603cb-537b-446b-bd68-badf657f29a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame columns: ['CleanTweet', 'label']\n",
      "Train DataFrame sample:\n",
      "                                          CleanTweet  label\n",
      "0  67,000 people died of drug use in 2019! Is ANY...      0\n",
      "1  Earlier today, CCBQ hosted a Pop-Up Food Distr...      1\n",
      "2  thank God for those recovering from Covid 19, ...      4\n",
      "3  How can you charge 999 INR (free shipping) for...      3\n",
      "4  New Jersey Division of Alcoholic Beverage Cont...      3\n"
     ]
    }
   ],
   "source": [
    "print(\"Train DataFrame columns:\", train_df.columns.tolist())\n",
    "print(\"Train DataFrame sample:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f2393e-72d5-4c1e-81db-1ab4d6d1267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myagelalfasi\u001b[0m (\u001b[33myagelalfasi-tau\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7a6038-6598-4833-a328-6de383be94e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/yagel/ADL/wandb/run-20250821_141400-5xknjiy8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/5xknjiy8' target=\"_blank\">eternal-elevator-26</a></strong> to <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/roBERTA-HF2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/5xknjiy8' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/5xknjiy8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 14:14:08,390] A new study created in memory with name: no-name-0cc97e29-335a-4174-851c-a6ec0218da21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 STARTING ENHANCED HYPERPARAMETER OPTIMIZATION WITH .PT CHECKPOINTS\n",
      "======================================================================\n",
      "🔬 Starting Enhanced Trial 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5xknjiy8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eternal-elevator-26</strong> at: <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/5xknjiy8' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/5xknjiy8</a><br/> View project at: <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/roBERTA-HF2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250821_141400-5xknjiy8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5xknjiy8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/yagel/ADL/wandb/run-20250821_141408-vhkk9p68</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/vhkk9p68' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/roBERTA-HF2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/vhkk9p68' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/vhkk9p68</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 02:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.104400</td>\n",
       "      <td>1.010108</td>\n",
       "      <td>0.579357</td>\n",
       "      <td>0.584482</td>\n",
       "      <td>0.579357</td>\n",
       "      <td>0.578859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='772' max='772' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [772/772 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████████████████████</td></tr><tr><td>final/accuracy</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████████████████████</td></tr><tr><td>train/eval/accuracy</td><td>▁▁</td></tr><tr><td>train/eval/f1</td><td>▁▁</td></tr><tr><td>train/eval/loss</td><td>▁▁</td></tr><tr><td>train/eval/precision</td><td>▁▁</td></tr><tr><td>train/eval/recall</td><td>▁▁</td></tr><tr><td>train/eval/runtime</td><td>▁█</td></tr><tr><td>train/eval/samples_per_second</td><td>█▁</td></tr><tr><td>train/eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████████████████████</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/train/loss</td><td>▁</td></tr><tr><td>train/train/runtime</td><td>▁</td></tr><tr><td>train/train/samples_per_second</td><td>▁</td></tr><tr><td>train/train/step_accuracy</td><td>▃▁▃▄▆▄▁▃▆▆▄▄▅▆▆▃▅▅▅█▄█▇▆▅▆▆▅▅▆▇▄▅▆▇▇▆▃▅▃</td></tr><tr><td>train/train/steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1.0</td></tr><tr><td>final/accuracy</td><td>0.57936</td></tr><tr><td>total_flos</td><td>3788901251481600.0</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/eval/accuracy</td><td>0.57936</td></tr><tr><td>train/eval/f1</td><td>0.57886</td></tr><tr><td>train/eval/loss</td><td>1.01011</td></tr><tr><td>train/eval/precision</td><td>0.58448</td></tr><tr><td>train/eval/recall</td><td>0.57936</td></tr><tr><td>train/eval/runtime</td><td>23.7244</td></tr><tr><td>train/eval/samples_per_second</td><td>520.266</td></tr><tr><td>train/eval/steps_per_second</td><td>32.54</td></tr><tr><td>train/global_step</td><td>1800</td></tr><tr><td>train/grad_norm</td><td>13.27751</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1044</td></tr><tr><td>train/train/loss</td><td>1.10438</td></tr><tr><td>train/train/runtime</td><td>149.9052</td></tr><tr><td>train/train/samples_per_second</td><td>192.121</td></tr><tr><td>train/train/step_accuracy</td><td>0.42857</td></tr><tr><td>train/train/steps_per_second</td><td>12.008</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/vhkk9p68' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/roBERTA-HF2/runs/vhkk9p68</a><br/> View project at: <a href='https://wandb.ai/yagelalfasi-tau/roBERTA-HF2' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/roBERTA-HF2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250821_141408-vhkk9p68/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 14:17:24,920] Trial 0 finished with value: 0.5793567204083286 and parameters: {'learning_rate': 1.4099284708689895e-05, 'weight_decay': 0.02096281486712023, 'batch_size': 16, 'num_layers_unfrozen': 5, 'patience': 5}. Best is trial 0 with value: 0.5793567204083286.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial 0 completed: Accuracy = 0.5794\n",
      "❌ Best trial checkpoint not found at checkpoints/roberta_study_20250821_141408/trial_0/model_checkpoint.pt\n",
      "\n",
      "============================================================\n",
      " ENHANCED ROBERTA OPTIMIZATION COMPLETED\n",
      "============================================================\n",
      "🏆 Best trial: 0\n",
      "📊 Best accuracy: 0.5794\n",
      "📋 Best hyperparameters:\n",
      "  learning_rate       : 1.41e-05\n",
      "  weight_decay        : 0.02096281486712023\n",
      "  batch_size          : 16\n",
      "  num_layers_unfrozen : 5\n",
      "  patience            : 5\n",
      "\n",
      "Best model checkpoints:\n",
      "  PyTorch: None\n",
      "  HuggingFace: None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BACKBONE = \"cardiffnlp/twitter-roberta-base-sentiment\"  #\"agentlans/deberta-v3-base-tweet-sentiment\"\n",
    "MAX_LENGTH = 256\n",
    "PROJECT = \"roBERTA-HF2\"\n",
    "SEED = 42\n",
    "EPOCHS =1 #20\n",
    "# Search space (same HPs, broader ranges)\n",
    "N_TRIALS = 1 # 10\n",
    "LR_RANGE = (5e-6, 5e-4)\n",
    "WD_RANGE = (1e-6, 1e-1)\n",
    "BATCH_CHOICES = [16, 32, 64]\n",
    "PATIENCE_RANGE = (1, 5)\n",
    "USE_LAYER_FREEZE = True  # set False to fine-tune all layers\n",
    "\n",
    "# Label mapping (5 classes)\n",
    "id2label = {\n",
    "    0: \"Extremely Negative\",\n",
    "    1: \"Negative\",\n",
    "    2: \"Neutral\",\n",
    "    3: \"Positive\",\n",
    "    4: \"Extremely Positive\",\n",
    "}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# -------------------- Reproducibility --------------------\n",
    "def set_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "set_seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "TEXT_COL = \"CleanTweet\"\n",
    "LABEL_COL = \"label\"\n",
    "\n",
    "if TEXT_COL not in train_df.columns:\n",
    "    raise ValueError(f\"Missing text column '{TEXT_COL}'. Found: {list(train_df.columns)}\")\n",
    "if LABEL_COL not in train_df.columns:\n",
    "    raise ValueError(f\"Missing label column '{LABEL_COL}'. Found: {list(train_df.columns)}\")\n",
    "\n",
    "if not np.issubdtype(train_df[LABEL_COL].dtype, np.number):\n",
    "    train_df[LABEL_COL] = train_df[LABEL_COL].astype(str).map(label2id)\n",
    "    eval_df[LABEL_COL]  = eval_df[LABEL_COL].astype(str).map(label2id)\n",
    "else:\n",
    "    train_df[LABEL_COL] = train_df[LABEL_COL].astype(int)\n",
    "    eval_df[LABEL_COL]  = eval_df[LABEL_COL].astype(int)\n",
    "\n",
    "unique_labels = sorted(pd.unique(train_df[LABEL_COL]))\n",
    "assert len(unique_labels) == 5, f\"Expected 5 classes, found {len(unique_labels)}\"\n",
    "assert set(unique_labels) == set(label2id.values()), \"Label mismatch with predefined mapping\"\n",
    "\n",
    "# -------------------- Tokenizer --------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(BACKBONE, use_fast=True)\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class TweetsCoronaDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer, text_col: str, label_col: str, max_length: int = 256):\n",
    "        self.texts = df[text_col].astype(str).tolist()\n",
    "        self.labels = df[label_col].astype(int).tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = TweetsCoronaDataset(train_df, tokenizer, TEXT_COL, LABEL_COL, MAX_LENGTH)\n",
    "eval_dataset  = TweetsCoronaDataset(eval_df,  tokenizer, TEXT_COL, LABEL_COL, MAX_LENGTH)\n",
    "\n",
    "# -------------------- Metrics (accuracy + precision/recall/F1) --------------------\n",
    "acc_metric  = evaluate.load(\"accuracy\")\n",
    "prec_metric = evaluate.load(\"precision\")\n",
    "rec_metric  = evaluate.load(\"recall\")\n",
    "f1_metric   = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\":  acc_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"precision\": prec_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"precision\"],\n",
    "        \"recall\":    rec_metric.compute(predictions=preds, references=labels,  average=\"weighted\")[\"recall\"],\n",
    "        \"f1\":        f1_metric.compute(predictions=preds, references=labels,   average=\"weighted\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "# -------------------- Model helpers --------------------\n",
    "def create_adapted_model():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        BACKBONE,\n",
    "        num_labels=5,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    model.config.id2label = id2label\n",
    "    model.config.label2id = label2id\n",
    "    return model\n",
    "\n",
    "def get_num_encoder_layers(model):\n",
    "    if hasattr(model, \"deberta\"):\n",
    "        return len(model.deberta.encoder.layer)\n",
    "    if hasattr(model, \"roberta\"):\n",
    "        return len(model.roberta.encoder.layer)\n",
    "    return 0\n",
    "\n",
    "def freeze_all_but_last_n(model, n_last: int):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    layers = None\n",
    "    if hasattr(model, \"deberta\"):\n",
    "        layers = model.deberta.encoder.layer\n",
    "        if hasattr(model.deberta, \"pooler\"):\n",
    "            for p in model.deberta.pooler.parameters():\n",
    "                p.requires_grad = True\n",
    "    elif hasattr(model, \"roberta\"):\n",
    "        layers = model.roberta.encoder.layer\n",
    "    if layers is not None:\n",
    "        n_total = len(layers)\n",
    "        start = max(0, n_total - max(0, n_last))\n",
    "        for i in range(start, n_total):\n",
    "            for p in layers[i].parameters():\n",
    "                p.requires_grad = True\n",
    "    for p in model.classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# -------------------- Custom Trainer (slash-only mapping + per-batch step accuracy) --------------------\n",
    "class CustomTrainer(Trainer):\n",
    "    def log(self, logs):\n",
    "        # Map any train_* / eval_* keys to slash-style before logging\n",
    "        if logs is None:\n",
    "            return\n",
    "        mapped = {}\n",
    "        for k, v in logs.items():\n",
    "            if isinstance(v, (np.floating,)):\n",
    "                v = float(v)\n",
    "            if isinstance(k, str) and k.startswith(\"train_\"):\n",
    "                mapped[f\"train/{k[6:]}\"] = v\n",
    "            elif isinstance(k, str) and k.startswith(\"eval_\"):\n",
    "                mapped[f\"eval/{k[5:]}\"] = v\n",
    "            else:\n",
    "                mapped[k] = v\n",
    "        super().log(mapped)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # follow HF logic; also log per-batch train/step_accuracy\n",
    "        if self.label_smoother is not None and \"labels\" in inputs:\n",
    "            labels = inputs.pop(\"labels\")\n",
    "        else:\n",
    "            labels = None\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        labels_in_batch = labels if labels is not None else inputs.get(\"labels\", None)\n",
    "        if labels_in_batch is not None and hasattr(outputs, \"logits\"):\n",
    "            with torch.no_grad():\n",
    "                preds = outputs.logits\n",
    "                pred_ids = preds.argmax(dim=-1)\n",
    "                correct = (pred_ids == labels_in_batch).sum().item()\n",
    "                total = labels_in_batch.numel()\n",
    "                step_acc = correct / max(1, total)\n",
    "                self.log({\"train/step_accuracy\": float(step_acc)})\n",
    "\n",
    "        if self.args.past_index >= 0:\n",
    "            self._past = outputs[self.args.past_index]\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.label_smoother(outputs, labels)\n",
    "        else:\n",
    "            loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# -------------------- Callbacks --------------------\n",
    "class TrainEvalCallback(TrainerCallback):\n",
    "    \"\"\"Evaluate on the training set at epoch 0 and each epoch end; log train/* metrics.\"\"\"\n",
    "    def __init__(self, train_dataset):\n",
    "        self.train_dataset = train_dataset\n",
    "\n",
    "    def _log_train_metrics(self, trainer, epoch_val):\n",
    "        m = trainer.evaluate(eval_dataset=self.train_dataset, metric_key_prefix=\"train\")\n",
    "        m = {k: (float(v) if isinstance(v, (int, float, np.floating)) else v) for k, v in m.items()}\n",
    "        m[\"epoch\"] = float(epoch_val)\n",
    "        trainer.log(m)  # CustomTrainer.log() converts to train/*\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        tr = kwargs.get(\"trainer\") or getattr(self, \"trainer\", None)\n",
    "        if tr is not None:\n",
    "            self._log_train_metrics(tr, 0.0)\n",
    "        return control\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        tr = kwargs.get(\"trainer\") or getattr(self, \"trainer\", None)\n",
    "        if tr is not None and state.epoch is not None:\n",
    "            self._log_train_metrics(tr, state.epoch)\n",
    "        return control\n",
    "\n",
    "class EnsureEpochCallback(TrainerCallback):\n",
    "    \"\"\"Guarantee 'epoch' is present so W&B uses it as the x-axis.\"\"\"\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if state.epoch is not None:\n",
    "            if logs is not None and \"epoch\" not in logs:\n",
    "                logs[\"epoch\"] = float(state.epoch)\n",
    "            try:\n",
    "                wandb.log({\"epoch\": float(state.epoch)}, commit=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "        return control\n",
    "\n",
    "# -------------------- W&B root run (epoch axis set immediately) --------------------\n",
    "wandb.init(project=PROJECT, config={\"backbone\": BACKBONE, \"max_length\": MAX_LENGTH, \"label_mapping\": id2label})\n",
    "wandb.define_metric(\"epoch\")\n",
    "wandb.define_metric(\"train/*\", step_metric=\"epoch\")\n",
    "wandb.define_metric(\"eval/*\",  step_metric=\"epoch\")\n",
    "wandb.define_metric(\"*\",       step_metric=\"epoch\")\n",
    "\n",
    "# -------------------- Enhanced Checkpoint Manager --------------------\n",
    "class HFCheckpointManager:\n",
    "    \"\"\"Enhanced checkpoint manager that saves both HuggingFace format and PyTorch .pt files\"\"\"\n",
    "    \n",
    "    def __init__(self, study_name=\"hf_roberta_study\", base_dir=\"checkpoints\"):\n",
    "        self.study_name = study_name\n",
    "        self.base_dir = base_dir\n",
    "        self.checkpoints_dir = os.path.join(base_dir, study_name)\n",
    "        os.makedirs(self.checkpoints_dir, exist_ok=True)\n",
    "        \n",
    "    def save_trial_checkpoint_pt(self, trial_number, model, tokenizer, metrics, hyperparameters, model_name):\n",
    "        \"\"\"Save trial checkpoint in .pt format using HuggingFace model.state_dict()\"\"\"\n",
    "        trial_dir = os.path.join(self.checkpoints_dir, f\"trial_{trial_number}\")\n",
    "        os.makedirs(trial_dir, exist_ok=True)\n",
    "        \n",
    "        # Prepare checkpoint data\n",
    "        checkpoint_data = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model_config': model.config.to_dict(),\n",
    "            'trial_number': trial_number,\n",
    "            'metrics': metrics,\n",
    "            'hyperparameters': hyperparameters,\n",
    "            'model_name': model_name,\n",
    "            'num_labels': model.config.num_labels,\n",
    "            'id2label': model.config.id2label,\n",
    "            'label2id': model.config.label2id,\n",
    "            'timestamp': time.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        }\n",
    "        \n",
    "        # Save .pt checkpoint\n",
    "        pt_path = os.path.join(trial_dir, \"model_checkpoint.pt\")\n",
    "        torch.save(checkpoint_data, pt_path)\n",
    "        \n",
    "        # Also save HuggingFace format for compatibility\n",
    "        hf_path = os.path.join(trial_dir, \"hf_model\")\n",
    "        model.save_pretrained(hf_path)\n",
    "        tokenizer.save_pretrained(hf_path)\n",
    "        \n",
    "        print(f\"💾 Trial {trial_number}: Saved checkpoints - Accuracy: {metrics.get('accuracy', 'N/A'):.4f}\")\n",
    "        return pt_path, hf_path\n",
    "    \n",
    "    def save_study_best_model_pt(self, best_trial_number, study_metrics):\n",
    "        \"\"\"Copy the best trial's checkpoint to a study-level best model directory\"\"\"\n",
    "        best_trial_dir = os.path.join(self.checkpoints_dir, f\"trial_{best_trial_number}\")\n",
    "        best_pt_path = os.path.join(best_trial_dir, \"model_checkpoint.pt\")\n",
    "        \n",
    "        if not os.path.exists(best_pt_path):\n",
    "            print(f\"❌ Best trial checkpoint not found at {best_pt_path}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Load and enhance best checkpoint\n",
    "        best_checkpoint = torch.load(best_pt_path, map_location='cpu')\n",
    "        study_best_dir = os.path.join(self.checkpoints_dir, \"best_model\")\n",
    "        os.makedirs(study_best_dir, exist_ok=True)\n",
    "        \n",
    "        study_best_checkpoint = {\n",
    "            **best_checkpoint,\n",
    "            'study_name': self.study_name,\n",
    "            'study_best_trial': best_trial_number,\n",
    "            'study_metrics': study_metrics,\n",
    "            'optimization_completed': time.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        }\n",
    "        \n",
    "        # Save study best model\n",
    "        study_pt_path = os.path.join(study_best_dir, \"best_model.pt\")\n",
    "        torch.save(study_best_checkpoint, study_pt_path)\n",
    "        \n",
    "        # Copy HuggingFace format\n",
    "        best_hf_dir = os.path.join(best_trial_dir, \"hf_model\")\n",
    "        study_hf_dir = os.path.join(study_best_dir, \"hf_model\")\n",
    "        \n",
    "        if os.path.exists(best_hf_dir):\n",
    "            import shutil\n",
    "            if os.path.exists(study_hf_dir):\n",
    "                shutil.rmtree(study_hf_dir)\n",
    "            shutil.copytree(best_hf_dir, study_hf_dir)\n",
    "        \n",
    "        print(f\"🏆 Study best model saved - Accuracy: {study_metrics.get('best_accuracy', 'N/A'):.4f}\")\n",
    "        return study_pt_path, study_hf_dir\n",
    "\n",
    "# Initialize checkpoint manager for RoBERTa\n",
    "checkpoint_manager = HFCheckpointManager(study_name=f\"roberta_study_{time.strftime('%Y%m%d_%H%M%S')}\")\n",
    "\n",
    "# -------------------- Enhanced Optuna objective with .pt checkpoints --------------------\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    trial_name = f\"trial_{trial.number}\"\n",
    "    print(f\"🔬 Starting Enhanced Trial {trial.number}\")\n",
    "    \n",
    "    wandb.init(project=PROJECT, name=trial_name, reinit=True)\n",
    "    wandb.define_metric(\"epoch\")\n",
    "    wandb.define_metric(\"train/*\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"eval/*\",  step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"*\",       step_metric=\"epoch\")\n",
    "\n",
    "    model = create_adapted_model()\n",
    "    total_layers = get_num_encoder_layers(model)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", LR_RANGE[0], LR_RANGE[1], log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", WD_RANGE[0], WD_RANGE[1], log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", BATCH_CHOICES),\n",
    "        \"num_layers_unfrozen\": trial.suggest_int(\"num_layers_unfrozen\", 2,6),\n",
    "        \"patience\": trial.suggest_int(\"patience\", PATIENCE_RANGE[0], PATIENCE_RANGE[1]),\n",
    "    }\n",
    "    wandb.config.update(params)\n",
    "\n",
    "    if USE_LAYER_FREEZE:\n",
    "        freeze_all_but_last_n(model, params[\"num_layers_unfrozen\"])\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./roberta_results_HF/{trial_name}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        per_device_train_batch_size=params[\"batch_size\"],\n",
    "        per_device_eval_batch_size=params[\"batch_size\"],\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=params[\"weight_decay\"],\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        report_to=\"wandb\",\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        save_total_limit=1,\n",
    "        run_name=trial_name,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    # Enhanced callback to save .pt checkpoints\n",
    "    class EnhancedCheckpointCallback(TrainerCallback):\n",
    "        def __init__(self, checkpoint_mgr, trial_num, hyperparams):\n",
    "            self.checkpoint_mgr = checkpoint_mgr\n",
    "            self.trial_num = trial_num\n",
    "            self.hyperparams = hyperparams\n",
    "            self.best_accuracy = 0.0\n",
    "            \n",
    "        def on_evaluate(self, args, state, control, model=None, tokenizer=None, logs=None, **kwargs):\n",
    "            if logs and \"eval_accuracy\" in logs:\n",
    "                current_accuracy = logs[\"eval_accuracy\"]\n",
    "                if current_accuracy > self.best_accuracy:\n",
    "                    self.best_accuracy = current_accuracy\n",
    "                    \n",
    "                    metrics = {\n",
    "                        \"accuracy\": current_accuracy,\n",
    "                        \"f1\": logs.get(\"eval_f1\", 0.0),\n",
    "                        \"precision\": logs.get(\"eval_precision\", 0.0),\n",
    "                        \"recall\": logs.get(\"eval_recall\", 0.0),\n",
    "                        \"epoch\": state.epoch\n",
    "                    }\n",
    "                    \n",
    "                    # Save checkpoint in .pt format\n",
    "                    self.checkpoint_mgr.save_trial_checkpoint_pt(\n",
    "                        self.trial_num, model, tokenizer, metrics, self.hyperparams, BACKBONE\n",
    "                    )\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[\n",
    "            EarlyStoppingCallback(early_stopping_patience=params[\"patience\"]),\n",
    "            TrainEvalCallback(train_dataset),\n",
    "            EnsureEpochCallback(),\n",
    "            EnhancedCheckpointCallback(checkpoint_manager, trial.number, params),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    wandb.log({\"final/accuracy\": eval_results.get(\"eval_accuracy\", float(\"nan\"))})\n",
    "    wandb.finish()\n",
    "    \n",
    "    print(f\"✅ Trial {trial.number} completed: Accuracy = {eval_results['eval_accuracy']:.4f}\")\n",
    "    return eval_results[\"eval_accuracy\"]\n",
    "\n",
    "# -------------------- Run Enhanced Optuna Study --------------------\n",
    "print(\"🎯 STARTING ENHANCED HYPERPARAMETER OPTIMIZATION WITH .PT CHECKPOINTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "# Save study-level best model with .pt checkpoints\n",
    "study_metrics = {\n",
    "    \"best_accuracy\": study.best_value,\n",
    "    \"best_trial\": study.best_trial.number,\n",
    "    \"best_params\": study.best_params,\n",
    "    \"total_trials\": len(study.trials),\n",
    "    \"completed_trials\": len([t for t in study.trials if t.value is not None])\n",
    "}\n",
    "\n",
    "best_pt_path, best_hf_path = checkpoint_manager.save_study_best_model_pt(\n",
    "    study.best_trial.number,\n",
    "    study_metrics\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" ENHANCED ROBERTA OPTIMIZATION COMPLETED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"🏆 Best trial: {study.best_trial.number}\")\n",
    "print(f\"📊 Best accuracy: {study.best_value:.4f}\")\n",
    "print(f\"📋 Best hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    if isinstance(value, float) and value < 0.001:\n",
    "        print(f\"  {key:20s}: {value:.2e}\")\n",
    "    else:\n",
    "        print(f\"  {key:20s}: {value}\")\n",
    "\n",
    "print(f\"\\nBest model checkpoints:\")\n",
    "print(f\"  PyTorch: {best_pt_path}\")\n",
    "print(f\"  HuggingFace: {best_hf_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "524f5bd2-d7a9-42de-97d2-7434cdf78a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 STARTING DEBERTA MODEL OPTIMIZATION\n",
      "======================================================================\n",
      "📋 DeBERTa Configuration:\n",
      "  Model: agentlans/deberta-v3-base-tweet-sentiment\n",
      "  Trials: 1 (same as RoBERTa)\n",
      "  Max epochs per trial: 1 (same as RoBERTa)\n",
      "  Learning rate range: (5e-06, 0.0005) (same as RoBERTa)\n",
      "  Batch size choices: [16, 32, 64] (same as RoBERTa)\n",
      "  Weight decay range: (1e-06, 0.1) (same as RoBERTa)\n",
      "  Patience range: (1, 5) (same as RoBERTa)\n",
      "🔧 Loading DeBERTa tokenizer and preparing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 14:17:25,427] A new study created in memory with name: deberta_sentiment_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DeBERTa datasets ready: Train=28800, Eval=12343\n",
      "\n",
      "🎯 STARTING DEBERTA HYPERPARAMETER OPTIMIZATION\n",
      "======================================================================\n",
      "\n",
      "🔬 Starting DeBERTa Trial 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/yagel/ADL/wandb/run-20250821_141725-7groneq0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA/runs/7groneq0' target=\"_blank\">deberta_trial_0</a></strong> to <a href='https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA/runs/7groneq0' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA/runs/7groneq0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at agentlans/deberta-v3-base-tweet-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 DeBERTa Trial 0 hyperparameters:\n",
      "  learning_rate: 1.90e-04\n",
      "  weight_decay: 7.83e-06\n",
      "  batch_size: 16\n",
      "  num_layers_unfrozen: 5\n",
      "  patience: 2\n",
      "🚀 Starting DeBERTa training for trial 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 03:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>0.803089</td>\n",
       "      <td>0.686948</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.686948</td>\n",
       "      <td>0.687342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='772' max='772' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [772/772 00:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████████████████████</td></tr><tr><td>final/accuracy</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████████████████████</td></tr><tr><td>train/eval/accuracy</td><td>▁▁</td></tr><tr><td>train/eval/f1</td><td>▁▁</td></tr><tr><td>train/eval/loss</td><td>▁▁</td></tr><tr><td>train/eval/precision</td><td>▁▁</td></tr><tr><td>train/eval/recall</td><td>▁▁</td></tr><tr><td>train/eval/runtime</td><td>▁█</td></tr><tr><td>train/eval/samples_per_second</td><td>█▁</td></tr><tr><td>train/eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇████████████████████</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/train/loss</td><td>▁</td></tr><tr><td>train/train/runtime</td><td>▁</td></tr><tr><td>train/train/samples_per_second</td><td>▁</td></tr><tr><td>train/train/step_accuracy</td><td>▃▃▁▆▆▅▂▅▅▅▃▃▅▆▇▄▆▃▆▇▅▆▇▆▅▇▆▃▅▅▇▅▄▄█▆▃▄▇▄</td></tr><tr><td>train/train/steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1.0</td></tr><tr><td>final/accuracy</td><td>0.68695</td></tr><tr><td>total_flos</td><td>3788969199206400.0</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/eval/accuracy</td><td>0.68695</td></tr><tr><td>train/eval/f1</td><td>0.68734</td></tr><tr><td>train/eval/loss</td><td>0.80309</td></tr><tr><td>train/eval/precision</td><td>0.69006</td></tr><tr><td>train/eval/recall</td><td>0.68695</td></tr><tr><td>train/eval/runtime</td><td>37.164</td></tr><tr><td>train/eval/samples_per_second</td><td>332.123</td></tr><tr><td>train/eval/steps_per_second</td><td>20.773</td></tr><tr><td>train/global_step</td><td>1800</td></tr><tr><td>train/grad_norm</td><td>4.19766</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.9885</td></tr><tr><td>train/train/loss</td><td>0.98847</td></tr><tr><td>train/train/runtime</td><td>222.2949</td></tr><tr><td>train/train/samples_per_second</td><td>129.558</td></tr><tr><td>train/train/step_accuracy</td><td>0.42857</td></tr><tr><td>train/train/steps_per_second</td><td>8.097</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deberta_trial_0</strong> at: <a href='https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA/runs/7groneq0' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA/runs/7groneq0</a><br/> View project at: <a href='https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA' target=\"_blank\">https://wandb.ai/yagelalfasi-tau/covid-tweets-sentiment-DEBERTA</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250821_141725-7groneq0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 14:21:59,801] Trial 0 finished with value: 0.6869480677306976 and parameters: {'learning_rate': 0.00018995358333354247, 'weight_decay': 7.834779300409089e-06, 'batch_size': 16, 'num_layers_unfrozen': 5, 'patience': 2}. Best is trial 0 with value: 0.6869480677306976.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DeBERTa Trial 0 completed: Accuracy = 0.6869\n",
      "❌ Best trial checkpoint not found at checkpoints/deberta_study_20250821_141724/trial_0/model_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# DEBERTA MODEL HYPERPARAMETER OPTIMIZATION\n",
    "# ==========================================\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"🤖 STARTING DEBERTA MODEL OPTIMIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# -------------------- DeBERTa Configuration --------------------\n",
    "DEBERTA_BACKBONE = \"agentlans/deberta-v3-base-tweet-sentiment\"\n",
    "DEBERTA_PROJECT = \"covid-tweets-sentiment-DeBERTa\"\n",
    "DEBERTA_EPOCHS = EPOCHS  # Same as RoBERTa (20 epochs)\n",
    "DEBERTA_N_TRIALS = N_TRIALS  # Same as RoBERTa (10 trials)\n",
    "\n",
    "# Use same hyperparameter ranges as RoBERTa for fair comparison\n",
    "DEBERTA_LR_RANGE = LR_RANGE  # (5e-6, 5e-4)\n",
    "DEBERTA_WD_RANGE = WD_RANGE  # (1e-6, 1e-1)\n",
    "DEBERTA_BATCH_CHOICES = BATCH_CHOICES  # [16, 32, 64]\n",
    "DEBERTA_PATIENCE_RANGE = PATIENCE_RANGE  # (1, 5)\n",
    "\n",
    "print(f\"📋 DeBERTa Configuration:\")\n",
    "print(f\"  Model: {DEBERTA_BACKBONE}\")\n",
    "print(f\"  Trials: {DEBERTA_N_TRIALS} (same as RoBERTa)\")\n",
    "print(f\"  Max epochs per trial: {DEBERTA_EPOCHS} (same as RoBERTa)\")\n",
    "print(f\"  Learning rate range: {DEBERTA_LR_RANGE} (same as RoBERTa)\")\n",
    "print(f\"  Batch size choices: {DEBERTA_BATCH_CHOICES} (same as RoBERTa)\")\n",
    "print(f\"  Weight decay range: {DEBERTA_WD_RANGE} (same as RoBERTa)\")\n",
    "print(f\"  Patience range: {DEBERTA_PATIENCE_RANGE} (same as RoBERTa)\")\n",
    "\n",
    "# -------------------- DeBERTa Model Creation --------------------\n",
    "def create_deberta_model():\n",
    "    \"\"\"Create DeBERTa model adapted for sentiment classification\"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        DEBERTA_BACKBONE,\n",
    "        num_labels=5,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    model.config.id2label = id2label\n",
    "    model.config.label2id = label2id\n",
    "    return model\n",
    "\n",
    "# Initialize checkpoint manager for DeBERTa\n",
    "deberta_checkpoint_manager = HFCheckpointManager(\n",
    "    study_name=f\"deberta_study_{time.strftime('%Y%m%d_%H%M%S')}\"\n",
    ")\n",
    "\n",
    "# -------------------- DeBERTa Tokenizer & Datasets --------------------\n",
    "print(\"🔧 Loading DeBERTa tokenizer and preparing datasets...\")\n",
    "deberta_tokenizer = AutoTokenizer.from_pretrained(DEBERTA_BACKBONE, use_fast=True)\n",
    "\n",
    "# Create DeBERTa datasets\n",
    "deberta_train_dataset = TweetsCoronaDataset(train_df, deberta_tokenizer, TEXT_COL, LABEL_COL, MAX_LENGTH)\n",
    "deberta_eval_dataset = TweetsCoronaDataset(eval_df, deberta_tokenizer, TEXT_COL, LABEL_COL, MAX_LENGTH)\n",
    "\n",
    "print(f\"✅ DeBERTa datasets ready: Train={len(deberta_train_dataset)}, Eval={len(deberta_eval_dataset)}\")\n",
    "\n",
    "# -------------------- DeBERTa Optuna Objective --------------------\n",
    "def deberta_objective(trial: optuna.trial.Trial):\n",
    "    \"\"\"Optuna objective function for DeBERTa hyperparameter optimization\"\"\"\n",
    "    trial_name = f\"deberta_trial_{trial.number}\"\n",
    "    print(f\"\\n🔬 Starting DeBERTa Trial {trial.number}\")\n",
    "    \n",
    "    # Initialize W&B for DeBERTa\n",
    "    wandb.init(project=DEBERTA_PROJECT, name=trial_name, reinit=True)\n",
    "    wandb.define_metric(\"epoch\")\n",
    "    wandb.define_metric(\"train/*\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"eval/*\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"*\", step_metric=\"epoch\")\n",
    "\n",
    "    # Create DeBERTa model\n",
    "    model = create_deberta_model()\n",
    "    total_layers = get_num_encoder_layers(model)\n",
    "\n",
    "    # DeBERTa hyperparameters (same ranges as RoBERTa)\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", DEBERTA_LR_RANGE[0], DEBERTA_LR_RANGE[1], log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", DEBERTA_WD_RANGE[0], DEBERTA_WD_RANGE[1], log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", DEBERTA_BATCH_CHOICES),\n",
    "        \"num_layers_unfrozen\": trial.suggest_int(\"num_layers_unfrozen\", 2, 6),  # Same range as RoBERTa\n",
    "        \"patience\": trial.suggest_int(\"patience\", DEBERTA_PATIENCE_RANGE[0], DEBERTA_PATIENCE_RANGE[1]),\n",
    "    }\n",
    "    wandb.config.update(params)\n",
    "    \n",
    "    print(f\"📋 DeBERTa Trial {trial.number} hyperparameters:\")\n",
    "    for key, value in params.items():\n",
    "        if isinstance(value, float) and value < 0.001:\n",
    "            print(f\"  {key}: {value:.2e}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "    if USE_LAYER_FREEZE:\n",
    "        freeze_all_but_last_n(model, params[\"num_layers_unfrozen\"])\n",
    "\n",
    "    # DeBERTa training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./deberta_results_HF/{trial_name}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        per_device_train_batch_size=params[\"batch_size\"],\n",
    "        per_device_eval_batch_size=params[\"batch_size\"],\n",
    "        num_train_epochs=DEBERTA_EPOCHS,\n",
    "        weight_decay=params[\"weight_decay\"],\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        report_to=\"wandb\",\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        save_total_limit=1,\n",
    "        run_name=trial_name,\n",
    "        seed=SEED,\n",
    "        # gradient_accumulation_steps=2,  # Removed for consistency with RoBERTa\n",
    "    )\n",
    "\n",
    "    # Enhanced callback for DeBERTa checkpoints\n",
    "    class DeBERTaCheckpointCallback(TrainerCallback):\n",
    "        def __init__(self, checkpoint_mgr, trial_num, hyperparams):\n",
    "            self.checkpoint_mgr = checkpoint_mgr\n",
    "            self.trial_num = trial_num\n",
    "            self.hyperparams = hyperparams\n",
    "            self.best_accuracy = 0.0\n",
    "            \n",
    "        def on_evaluate(self, args, state, control, model=None, tokenizer=None, logs=None, **kwargs):\n",
    "            if logs and \"eval_accuracy\" in logs:\n",
    "                current_accuracy = logs[\"eval_accuracy\"]\n",
    "                if current_accuracy > self.best_accuracy:\n",
    "                    self.best_accuracy = current_accuracy\n",
    "                    \n",
    "                    metrics = {\n",
    "                        \"accuracy\": current_accuracy,\n",
    "                        \"f1\": logs.get(\"eval_f1\", 0.0),\n",
    "                        \"precision\": logs.get(\"eval_precision\", 0.0),\n",
    "                        \"recall\": logs.get(\"eval_recall\", 0.0),\n",
    "                        \"epoch\": state.epoch\n",
    "                    }\n",
    "                    \n",
    "                    # Save DeBERTa checkpoint in .pt format\n",
    "                    self.checkpoint_mgr.save_trial_checkpoint_pt(\n",
    "                        self.trial_num, model, tokenizer, metrics, self.hyperparams, DEBERTA_BACKBONE\n",
    "                    )\n",
    "\n",
    "    # Create DeBERTa trainer\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=deberta_train_dataset,\n",
    "        eval_dataset=deberta_eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[\n",
    "            EarlyStoppingCallback(early_stopping_patience=params[\"patience\"]),\n",
    "            TrainEvalCallback(deberta_train_dataset),\n",
    "            EnsureEpochCallback(),\n",
    "            DeBERTaCheckpointCallback(deberta_checkpoint_manager, trial.number, params),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Train DeBERTa model\n",
    "    print(f\"🚀 Starting DeBERTa training for trial {trial.number}\")\n",
    "    trainer.train()\n",
    "    \n",
    "    # Get final evaluation results\n",
    "    eval_results = trainer.evaluate()\n",
    "    final_accuracy = eval_results[\"eval_accuracy\"]\n",
    "    \n",
    "    # Log final results to W&B\n",
    "    wandb.log({\"final/accuracy\": final_accuracy})\n",
    "    wandb.finish()\n",
    "    \n",
    "    print(f\"✅ DeBERTa Trial {trial.number} completed: Accuracy = {final_accuracy:.4f}\")\n",
    "    return final_accuracy\n",
    "\n",
    "# -------------------- Run DeBERTa Optuna Study --------------------\n",
    "print(\"\\n🎯 STARTING DEBERTA HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create and run DeBERTa study\n",
    "deberta_study = optuna.create_study(direction=\"maximize\", study_name=\"deberta_sentiment_study\")\n",
    "deberta_study.optimize(deberta_objective, n_trials=DEBERTA_N_TRIALS)\n",
    "\n",
    "# Save DeBERTa study-level best model\n",
    "deberta_study_metrics = {\n",
    "    \"best_accuracy\": deberta_study.best_value,\n",
    "    \"best_trial\": deberta_study.best_trial.number,\n",
    "    \"best_params\": deberta_study.best_params,\n",
    "    \"total_trials\": len(deberta_study.trials),\n",
    "    \"completed_trials\": len([t for t in deberta_study.trials if t.value is not None])\n",
    "}\n",
    "\n",
    "deberta_best_pt_path, deberta_best_hf_path = deberta_checkpoint_manager.save_study_best_model_pt(\n",
    "    deberta_study.best_trial.number,\n",
    "    deberta_study_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b0fdc37-a6f8-457e-aab5-aa3a6be7a054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🔍 MODEL COMPARISON: RoBERTa vs DeBERTa\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roberta_best_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔍 MODEL COMPARISON: RoBERTa vs DeBERTa\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🤖 RoBERTa Best Accuracy:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroberta_best_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🤖 DeBERTa Best Accuracy:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeberta_study\u001b[38;5;241m.\u001b[39mbest_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deberta_study\u001b[38;5;241m.\u001b[39mbest_value \u001b[38;5;241m>\u001b[39m roberta_best_accuracy:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roberta_best_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------- Model Comparison --------------------\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"🔍 MODEL COMPARISON: RoBERTa vs DeBERTa\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"🤖 RoBERTa Best Accuracy:  {roberta_best_accuracy:.4f}\")\n",
    "print(f\"🤖 DeBERTa Best Accuracy:  {deberta_study.best_value:.4f}\")\n",
    "\n",
    "if deberta_study.best_value > roberta_best_accuracy:\n",
    "    improvement = deberta_study.best_value - roberta_best_accuracy\n",
    "    print(f\"🏆 DeBERTa wins by {improvement:.4f} points! ({improvement/roberta_best_accuracy*100:.2f}% improvement)\")\n",
    "elif roberta_best_accuracy > deberta_study.best_value:\n",
    "    improvement = roberta_best_accuracy - deberta_study.best_value\n",
    "    print(f\"🏆 RoBERTa wins by {improvement:.4f} points! ({improvement/deberta_study.best_value*100:.2f}% improvement)\")\n",
    "else:\n",
    "    print(\"🤝 It's a tie! Both models perform equally well.\")\n",
    "\n",
    "print(f\"\\n📊 Summary:\")\n",
    "print(f\"  📈 RoBERTa trials: {len([t for t in study.trials if t.value is not None])}\")\n",
    "print(f\"  📈 DeBERTa trials: {len([t for t in deberta_study.trials if t.value is not None])}\")\n",
    "print(f\"  🎯 Best overall model: {'DeBERTa' if deberta_study.best_value > roberta_best_accuracy else 'RoBERTa'}\")\n",
    "\n",
    "# Store results for future reference\n",
    "deberta_best_accuracy = deberta_study.best_value\n",
    "deberta_best_params = deberta_study.best_params\n",
    "\n",
    "print(\"\\n✅ Both model optimizations completed with .pt checkpoint saving!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e15d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING MANUALLY SELECTED CHECKPOINTS\n",
      "============================================================\n",
      "\n",
      "EVALUATING ROBERTA MODEL\n",
      "----------------------------------------\n",
      "\n",
      "🔎 Looking for RoBERTa checkpoint...\n",
      "✅ Found: roberta_results_HF/trial_7/checkpoint-18000/model.safetensors\n",
      "📦 Loading RoBERTa from: roberta_results_HF/trial_7/checkpoint-18000/model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating RoBERTa on 3798 samples...\n",
      " RoBERTa Results:\n",
      "   Accuracy:  0.7401\n",
      "   Precision: 0.7507\n",
      "   Recall:    0.7401\n",
      "   F1-Score:  0.7417\n",
      "Predicted labels saved to test_set_results_RoBERTa.csv\n",
      "\n",
      "EVALUATING DEBERTA MODEL\n",
      "----------------------------------------\n",
      "\n",
      "🔎 Looking for DeBERTa checkpoint...\n",
      "✅ Found: deberta_results_HF/deberta_trial_4/checkpoint-4950/model.safetensors\n",
      "📦 Loading DeBERTa from: deberta_results_HF/deberta_trial_4/checkpoint-4950/model.safetensors\n",
      "🔍 Evaluating DeBERTa on 3798 samples...\n",
      " DeBERTa Results:\n",
      "   Accuracy:  0.7033\n",
      "   Precision: 0.7071\n",
      "   Recall:    0.7033\n",
      "   F1-Score:  0.7042\n",
      "Predicted labels saved to test_set_results_DeBERTa.csv\n",
      "\n",
      "============================================================\n",
      "FINAL COMPARISON\n",
      "============================================================\n",
      "RoBERTa :      0.7401 accuracy\n",
      "DeBERTa : 0.7033 accuracy\n",
      "\n",
      "🏆WINNER: RoBERTa (+0.0369 advantage)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "# Load test_df\n",
    "test_df = pd.read_csv(\"data/test_df.csv\")\n",
    "\n",
    "def find_checkpoint_files(checkpoint_dir):\n",
    "    \"\"\"Find all checkpoint files in a directory and subdirectories\"\"\"\n",
    "    \n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        print(f\"❌ Directory does not exist: {checkpoint_dir}\")\n",
    "        return None\n",
    "   \n",
    "    # Look for checkpoint files in common locations\n",
    "    possible_files = [\n",
    "        \"pytorch_model.bin\",\n",
    "        \"model.safetensors\", \n",
    "        \"best_model.pt\",\n",
    "        \"model_checkpoint.pt\",\n",
    "        \"checkpoint.pt\",\n",
    "        \"model.pt\"\n",
    "    ]\n",
    "    \n",
    "    found_files = []\n",
    "    \n",
    "    # Check main directory\n",
    "    for filename in possible_files:\n",
    "        filepath = os.path.join(checkpoint_dir, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            found_files.append(filepath)\n",
    "            print(f\"✅ Found: {filepath}\")\n",
    "    \n",
    "    # Check subdirectories\n",
    "    for item in os.listdir(checkpoint_dir):\n",
    "        item_path = os.path.join(checkpoint_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            for filename in possible_files:\n",
    "                filepath = os.path.join(item_path, filename)\n",
    "                if os.path.exists(filepath):\n",
    "                    found_files.append(filepath)\n",
    "                    print(f\"✅ Found: {filepath}\")\n",
    "    \n",
    "    return found_files[0] if found_files else None\n",
    "\n",
    "def evaluate_model_from_checkpoint(model_type, backbone, checkpoint_dir):\n",
    "    \"\"\"Evaluate a model from a specific checkpoint directory using test_df\"\"\"\n",
    "    print(f\"\\nLooking for {model_type} checkpoint...\")\n",
    "    checkpoint_path = find_checkpoint_files(checkpoint_dir)\n",
    "    \n",
    "    if checkpoint_path is None:\n",
    "        print(f\"❌ No checkpoint file found in {checkpoint_dir}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loading {model_type} from: {checkpoint_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(backbone, use_fast=True)\n",
    "        \n",
    "        # Load model based on checkpoint type\n",
    "        if checkpoint_path.endswith(('.bin', '.safetensors')):\n",
    "            # Standard HuggingFace checkpoint - load from directory\n",
    "            model_dir = os.path.dirname(checkpoint_path)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                model_dir, \n",
    "                num_labels=5, \n",
    "                ignore_mismatched_sizes=True\n",
    "            )\n",
    "        else:\n",
    "            # Custom .pt checkpoint\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                backbone, \n",
    "                num_labels=5, \n",
    "                ignore_mismatched_sizes=True\n",
    "            )\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        # Prepare test data\n",
    "        test_dataset = TweetsCoronaDataset(test_df, tokenizer, \"CleanTweet\", \"label\", 256)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "        \n",
    "        # Evaluate\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        print(f\"🔍 Evaluating {model_type} on {len(test_dataset)} samples...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                outputs = model(\n",
    "                    batch['input_ids'].to(device), \n",
    "                    attention_mask=batch['attention_mask'].to(device)\n",
    "                )\n",
    "                all_preds.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
    "                all_labels.extend(batch['labels'].cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='weighted'\n",
    "        )\n",
    "        \n",
    "        print(f\" {model_type} Results:\")\n",
    "        print(f\"   Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"   Precision: {precision:.4f}\")\n",
    "        print(f\"   Recall:    {recall:.4f}\")\n",
    "        print(f\"   F1-Score:  {f1:.4f}\")\n",
    "        \n",
    "        # Save predicted labels to test_df\n",
    "        test_df[f'{model_type}_predicted_label'] = all_preds\n",
    "        test_df.to_csv(f'test_set_results_{model_type}_HF.csv', index=False)\n",
    "        print(f\"Predicted labels saved to test_set_results_{model_type}.csv\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy, \n",
    "            'precision': precision, \n",
    "            'recall': recall, \n",
    "            'f1': f1,\n",
    "            'checkpoint_path': checkpoint_path\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {model_type} evaluation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Manual checkpoint specification\n",
    "print(\"EVALUATING MANUALLY SELECTED CHECKPOINTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Your manually specified checkpoint paths\n",
    "roberta_checkpoint_dir = \"roberta_results_HF/trial_7\"\n",
    "deberta_checkpoint_dir = \"deberta_results_HF/deberta_trial_4\"\n",
    "\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Evaluate RoBERTa\n",
    "print(f\"\\nEVALUATING ROBERTA MODEL\")\n",
    "print(\"-\" * 40)\n",
    "results['RoBERTa'] = evaluate_model_from_checkpoint(\n",
    "    \"RoBERTa\", \n",
    "    \"cardiffnlp/twitter-roberta-base-sentiment\", \n",
    "    roberta_checkpoint_dir\n",
    ")\n",
    "\n",
    "# Evaluate DeBERTa  \n",
    "print(f\"\\nEVALUATING DEBERTA MODEL\")\n",
    "print(\"-\" * 40)\n",
    "results['DeBERTa'] = evaluate_model_from_checkpoint(\n",
    "    \"DeBERTa\", \n",
    "    \"agentlans/deberta-v3-base-tweet-sentiment\", \n",
    "    deberta_checkpoint_dir\n",
    ")\n",
    "\n",
    "# Compare results\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print( \"FINAL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if results.get('RoBERTa') and results.get('DeBERTa'):\n",
    "    roberta_acc = results['RoBERTa']['accuracy']\n",
    "    deberta_acc = results['DeBERTa']['accuracy']\n",
    "    \n",
    "    print(f\"RoBERTa :      {roberta_acc:.4f} accuracy\")\n",
    "    print(f\"DeBERTa : {deberta_acc:.4f} accuracy\")\n",
    "    \n",
    "    if deberta_acc > roberta_acc:\n",
    "        margin = deberta_acc - roberta_acc\n",
    "        print(f\"\\n WINNER: DeBERTa (+{margin:.4f} advantage)\")\n",
    "    elif roberta_acc > deberta_acc:\n",
    "        margin = roberta_acc - deberta_acc\n",
    "        print(f\"\\n🏆WINNER: RoBERTa (+{margin:.4f} advantage)\")\n",
    "    else:\n",
    "        print(f\"\\n TIE: Both models perform equally well!\")\n",
    "        \n",
    "elif results.get('RoBERTa'):\n",
    "    print(f\"RoBERTa only: {results['RoBERTa']['accuracy']:.4f} accuracy\")\n",
    "elif results.get('DeBERTa'):\n",
    "    print(f\" DeBERTa only: {results['DeBERTa']['accuracy']:.4f} accuracy\")\n",
    "else:\n",
    "    print(\"❌ No models could be evaluated\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "evaluation_results = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18d94acc-fd26-4399-9d33-3110e4eb126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Results saved to: model_evaluation_results_HF_20250821_142300.csv\n",
      "\n",
      "Saved results:\n",
      "  Model  Test_Accuracy  Test_Precision  Test_Recall  Test_F1_Score     Evaluation_Date  Dataset_Size                            Model_Backbone\n",
      "RoBERTa       0.740126        0.750679     0.740126       0.741690 2025-08-21 14:23:00          3798 cardiffnlp/twitter-roberta-base-sentiment\n",
      "DeBERTa       0.703265        0.707051     0.703265       0.704158 2025-08-21 14:23:00          3798 agentlans/deberta-v3-base-tweet-sentiment\n",
      "\n",
      "🏆 Best performing model: RoBERTa with 0.7401 accuracy\n"
     ]
    }
   ],
   "source": [
    "# Save evaluation results to CSV\n",
    "\n",
    "# Create a comprehensive results DataFrame\n",
    "results_data = []\n",
    "\n",
    "for model_name, metrics in evaluation_results.items():\n",
    "    if metrics is not None:\n",
    "        result_row = {\n",
    "            'Model': model_name,\n",
    "            'Test_Accuracy': metrics['accuracy'],\n",
    "            'Test_Precision': metrics['precision'],\n",
    "            'Test_Recall': metrics['recall'],\n",
    "            'Test_F1_Score': metrics['f1'],\n",
    "            'Evaluation_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'Dataset_Size': len(test_df),\n",
    "            'Model_Backbone': 'cardiffnlp/twitter-roberta-base-sentiment' if model_name == 'RoBERTa' else 'agentlans/deberta-v3-base-tweet-sentiment'\n",
    "        }\n",
    "        results_data.append(result_row)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "if results_data:\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Save to CSV with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    csv_filename = f'model_evaluation_results_HF_{timestamp}.csv'\n",
    "    results_df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    print(f\"📊 Results saved to: {csv_filename}\")\n",
    "    print(\"\\nSaved results:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Also save a summary comparison\n",
    "    if len(results_data) > 1:\n",
    "        best_model = results_df.loc[results_df['Test_Accuracy'].idxmax()]\n",
    "        print(f\"\\n🏆 Best performing model: {best_model['Model']} with {best_model['Test_Accuracy']:.4f} accuracy\")\n",
    "else:\n",
    "    print(\"❌ No evaluation results to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc8a02c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af975e6-a856-4724-b36b-048385ec8f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
